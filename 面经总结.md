## 机器学习

### 机器学习的性能评估指标

#### 错误率，精度

###### 错误率: 分类错误的样本数占总样本的比例

$$
    Error = \frac{1}{m}\sum_{i=1}^msign(f(x_i)!=y_i)
$$

##### 精度：分类正确的样本占总样本的比例

$$
    Acc = \frac{1}{m}\sum_{i=1}^msign(f(x_i)==y_i)
$$

##### 缺点：对于类别不平衡的数据集，不能体现出模型对占比小的类别的判断能力。



#### 混淆矩阵，查准率，查全率，F1

##### 混淆矩阵：将样例的**真实类别**和学习器的**预测类别**组合划分为TP，FP，TN，FN

记忆方法：TF表示预测结果的正确与错误，PN表示预测结果的正例和反例

|          | 预测结果 |      |
| -------- | -------- | :--- |
| 真实情况 | 正例     | 反例 |
| 正例     | TP       | FN   |
| 反例     | FP       | TN   |




##### 查准率:在学习器预测为正例的情况下，正确的概率

$$
P = \frac{TP}{TP+FP}
$$

##### 查全率: 在所有正样本中，模型判断为正样本的概率

$$
    R = \frac{TP}{TP+FN}
$$

##### PR曲线：调整二分类的判断阈值，获得一个混淆矩阵，及相关查准率和查全率。

用途：

1. 选择最好的分类阈值
2. 判断模型的优劣，越外面越好，说明区分度非常大

##### F1值:查准率和查全率的调和平均
$$
    F1 = \frac{2*P*R}{P+R}
$$

##### 多分类的问题

1. Marco: 把n分类问题看成n个二分类问题计算出各自的PR, (P1, R1),(P2, R2),...,(Pn, Rn),直接对$P_i,R_i$进行平均
2. Micro: 把n分类问题看成n个二分类问题计算出各自 $(TP_i,FP_i,TN_i,FN_i)$的值再做平均


##### ROC和AUC

ROC类似PR曲线,都是使用不同的阈值来计算特征值后进行描点画图，但ROC的的特征值为TPR和FPR

$$
    TPR = \frac{TP}{TP +  FN} \\
    FPR = \frac{FP}{TN + FP}
$$

整两个特征的含义：
1. TPR: 在实际为正样本的结果中，判断正确的比例
2. FPR: 在实际为负样本的结果，判断正的比率

AUC则是ROC曲线和坐标轴所夹的面积

最后说说AUC的优势，AUC的计算方法同时考虑了分类器对于正例和负例的分类能力，在样本不平衡的情况下，依然能够对分类器作出合理的评价。例如在反欺诈场景，设欺诈类样本为正例，正例占比很少（假设0.1%），如果使用准确率评估，把所有的样本预测为负例，便可以获得99.9%的准确率。但是如果使用AUC，把所有样本预测为负例，TPRate和FPRate同时为0（没有Positive），与(0,0) (1,1)连接，得出AUC仅为0.5，成功规避了样本不均匀带来的问题。

### 决策树，GBDT，XGBooost

#### 决策树

##### 定义：决策树是一种基本的分类和回归方法

- 决策树由节点和有向边构成，节点可以分为叶节点和非叶节点，叶节点表示一个类，非叶节点表示一个属性或特征。可以将决策树看成一个if-then的规则集合，从根节点出发，到叶节点的每一条路径可以构成一条规则。

- 从概率空间上，一般决策树的分类面多为一个阶梯状的分类面


##### 决策树生成通用流程

决策树的生成过程主要为贪婪方法: 选择让分类纯度上升最大的特征以及该特征的分类面->分类-> 开始下一个节点，

选择特征和特征分类面主要依据选择该操作后分类结果的纯度，可以使用 信息增益(ID3), 信息增益比(C4.5), Geni系数(CART)


##### ID3, C4.5, CART生成决策树

###### ID3:

决策树在各个节点上应用信息增益准则选择特征，递归地构建决策树。从根节点开始，计算对所有可能的特征的**信息增益**(意味着只能针对离散取值的特征变量)，选择最大的特征作为节点的特征，有该**特征的不同取值**(意味着只能针对离散取值的特征变量)建立节点;再对子节点不断递归调用构建决策树, 直到所有特征的信息增益均很小，或者没有特征可以选择。背后的实际上是用极大似然估计进行概率模型的选择。

###### C4.5

生成流程与ID3类似，但是用的信息增益比来选择特征，这样可以缓解偏向选择去数量较多的特征。

$$
    g(D, A) = H(D) - H(D|A) \\
    = -\sum_{k=1}^K \frac{|C_k|}{|D|}log_2\frac{|C_k|}{|D|} - (-\sum_{i=1}^n{\frac{|D_i|}{|D|}}\sum_{k=1}^K \frac{|C_k|}{|D|}log_2\frac{|C_k|}{|D|})
$$

连续变量的处理方法：

二分法，将所有该特征的取值排序，穷举每个数据之间的均值进行划分点，计算


**剪枝**

剪枝的通过及消化决策树的整体损失函数(带有正则项(结构风险))的损失函数来评估，自底而上的进行

###### CART

可以用于分类和回归的决策树，依旧是特征选择 -> 树的生成 -> 剪枝。

回归树用平方误差最小，分类树用基尼指数。

基尼系数，假设有K个类，样本点是k的概率为$p_k$，则概率分布的基尼系数为

$$
Gini(p) = \sum_{k=1}^Kp_k(1-p_k) = 1 - \sum_{k=1}^Kp_k^2
$$

**CART剪枝**

$$
    C_\alpha(t) = C(t) + \alpha \\
    C_\alpha(T_t) = C(T_t) + \alpha |T_t|           两者做差\\
    g(t) = \alpha = \frac{C(t)-C(T_t)}{|T_t|-1} 
$$

$$
    g(t) = \frac{C(t)-C(T_t)}{|T_t|-1} \\ 
$$

在原有剪枝的基础上进行剪枝，然后每做一个操作形成一个子树，将子树序列保存，利用交叉验证的方法，在肚里的验证数据集上进行测试，选择最优的子树。

### Bagging与Boosting

#### Bagging:

自助采样法，给定m个样本的数据集，有放回的取出n个样本，抽取T次，得到T个容量为n的样本集，然后每个样本集都训练出一个基学习器，然后在结合（一般是简单的投票法和平均法），Bagging的流程，复杂度T(O(m) + O(s))

优点:
- 泛化性能，可以使用包外估计（也就是抽出来的样本集不是整个训练集，剩下数据可以用作验证集，进行参数选择和减小过拟合的风险）
- 降低方差

#### 随机森林

随机森林是在Bagging集成的基础上，进一步引入随机属性选择，两个特点：
- Bagging数据侧
- 随机选择特征进行训练，模型侧

实现策略：
1. Bagging抽取不同的数据样本集
2. 训练时，随机从总数d个属性中抽取k个进行分类器的训练，经验上选择就是 $k = log_2d$

优点：

- 随机森林算法能解决分类与回归两种类型的问题，表现良好，由于是集成学习，方差和偏差都比较低，泛化性能优越；
- 随机森林对于高维数据集的处理能力很好，它可以处理成千上万的输入变量，并确定最重要的变量，因此被认为是一个不错的降维方法。此外，**该模型能够输出特征的重要性程度**，两个方法，对于某个特征，1.观察信息增益 2.观察袋内准确率的下降程度
- 可以应对缺失数据；
- 当存在分类不平衡的情况时，随机森林能够提供平衡数据集误差的有效方法；
- 高度并行化，易于分布式实现
- 由于是树模型 ，不需要归一化即可直接使用

缺点：
- 随机森林在解决回归问题时并没有像它在分类中表现的那么好，这是因为它并不能给出一个连续型的输出。当进行回归时，随机森林不能够作出超越训练集数据范围的预测，这可能导致在对某些还有特定噪声的数据进行建模时出现过度拟合。
- 对于许多统计建模者来说，随机森林给人的感觉像是一个黑盒子——你几乎无法控制模型内部的运行，只能在不同的参数和随机种子之间进行尝试。
- 忽略属性之间的相关性，假设各个特征之间是正交的

#### Boosting



#### GBDT:梯度提升决策树

GBDT是一种集成学习的方法,基学习器是CART,基学习器的输出为连续值,但既适用于分类也适用于回归。

##### 主要思路：

假设GBDT有k个CART决策树，第k个位
$$
    T_k(x)
$$

前k个的预测值可以写为
$$
f_k(x)= \sum_{i=1}^kT_i(x)
$$

**GBDT是一个加法模型**,他把所有的基础模型的预测值假期来作为最终的预测值。其递归形式为:

$$
f_k(x) = f_{k-1}(x)+T_k(x)
$$

训练第k个CART的时候，我们需要最小化这样一个目标函数。

$$
J=\sum_{n=1}^{N} \mathrm{~L}\left(\mathrm{y}_{n}, f_{k}\left(x_{n}\right)\right)=\sum_{n=1}^{N} \mathrm{~L}\left(\mathrm{y}_{n}, f_{k-1}\left(x_{n}\right)+T_{k}(x)\right)
$$

为了优化目标函数，我们需要**使用基函数来进行梯度迭代**
$$
f_{k}\left(x_{n}\right)=f_{k-1}\left(x_{n}\right)-\text {学习率*} \frac{\partial J}{\partial f_{k-1}}
$$

这个公式的含义是：**GBDT的每一棵CART的任务，是拟合之前所有CART留下的残差。**

使用的方法就是: **计算梯度，然后把算出来的梯度作为下一个基学习器的y**。

##### 用于分类问题

这其实类似于深度网络，如果不加sigmoid或softmax，其实神经网络输出的也是个实数，也是回归问题，但如果我们用这些损失函数约束后就可以用作分类了，但是需要计算各种的梯度。






#### XGBoost:GBDT加强版

数学上的差别

1. 引入了正则项，防止过拟合;
2. 使用二阶泰勒展开的逼近目标

工程上的差别：
1. 传统的GBDT采用CART作为基分类器，XGBoost支持多种类型的基分类 器，比如线性分类器。
2. 传统的GBDT在每轮迭代时使用全部的数据，XGBoost则采用了与随机 森林相似的策略，支持对数据进行采样。


##### 正则项：

XGBoost的树的复杂度


### 如何解决过拟合



### 数据不平衡问题

模型层面：

数据层面：
1. 欠采样
2. 过采样
3. 阈值移动（代价敏感学习）






## 深度学习

### 1. 参数初始化问题




### 2. word2vec以及维度的确定

词向量就是词语把高维度稀疏独热编码为低维度的向量表示的方法。常用的实现方法word2vec,Glove

#### word2vec:

背后的语言学基础：有同样上下文的词意义相近。

CBOW：用窗口内上下文词预测中心词

Skip-gram: 用中心词预测上下文的词

##### 加速

1. 负采样：然后负样本的数量非常多，这个就是样本数量极度不均衡的状态，所以我们需要从负样本里面抽选一部分出来，这样的话，我们计算的时候就更快。一般的抽取方法，可以按照词频,但是也有其他的选择方法。
2. 层级softmax;


#### Glove

Glove认为Word2vec只考虑词的局部信息(即上下文窗口内),没有考虑到词与局部窗口外词的联系，glove利用共现矩阵，同时考虑了局部信息和整体的信息。


### 3.  LSTM和梯度爆炸和弥散

#### 一切从RNN的梯度爆炸和梯度弥散开始说起

RNN公式

$$
    h_t = f(Uh_{t-1} + Wx_t + b) \\
    y_t = Vh_t
$$

RNN好吗？好啊，通用近似定理保证了可以拟合任意的有界笔记上的任意连续函数；而且是图灵完备的(Transformers不是图灵完备的)


##### 梯度的爆炸与弥散

链式法则：复合函数求导，等于各个函数的导数相乘

当序列长度非常长的时候，导数的连乘会非常大或非常小，非常大导致模型不稳定（NaN），梯度非常小，导致前面的信息无法传导到后面。

由 1 中所述的原因，**RNN 中总的梯度是不会消失的**。即便梯度越传越弱，那也只是远距离的梯度消失，由于近距离的梯度不会消失，所有梯度之和便不会消失。**RNN 所谓梯度消失的真正含义是，梯度被近距离梯度主导，导致模型难以学到远距离的依赖关系。**

#### LSTM的改进方案
$$
\left[\begin{array}{c}
\tilde{c}_{t} \\
\boldsymbol{o}_{t} \\
\boldsymbol{i}_{t} \\
\boldsymbol{f}_{t}
\end{array}\right]=\left[\begin{array}{c}
\tanh \\
\sigma \\
\sigma \\
\sigma
\end{array}\right]\left(\boldsymbol{W}\left[\begin{array}{c}
\boldsymbol{x}_{t} \\
\boldsymbol{h}_{t-1}
\end{array}\right]+\boldsymbol{b}\right)\\

\boldsymbol{c}_{t}=\boldsymbol{f}_{t} \odot \boldsymbol{c}_{t-1}+\boldsymbol{i}_{t} \odot \tilde{\boldsymbol{c}}_{t} \\

\boldsymbol{h}_{t}=\boldsymbol{o}_{t} \odot tanh({\boldsymbol{c}}_{t})
$$

在神经网络中，长期记忆 （ Long-Term Memory）可以看作是网络参数，隐含了从训练数据中学到的经验，其更新周期要远远慢于短期记忆。

而在 LSTM 网络中，记忆单元 c 可以在某个时刻捕捉到某个关键信息，并有能力将此关键信息保存一定的时间间隔。记忆单元 c中保存信息的生命周期要长于短期记忆 h，但又远远短于长期记忆

从反向回传的角度来说，$\boldsymbol{c}_{t}=\boldsymbol{f}_{t} \odot \boldsymbol{c}_{t-1}+\boldsymbol{i}_{t} \odot \tilde{\boldsymbol{c}}_{t}$这条道路是没有复合函数的，只有加和乘，c可以快速的回传回去，其他的渠道还是需要多次计算

### 4. Transformer原理和Position Embedding



### 5. L1和L2的正则化